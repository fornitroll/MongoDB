{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f853fe2e-118e-44f8-a90f-bd34c7a97594",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "### The ‘CAP’ in the CAP theorem, explained (https://www.ibm.com/cloud/learn/cap-theorem)\n",
    "\n",
    "Let’s take a detailed look at the three distributed system characteristics to which the CAP theorem refers.\n",
    "\n",
    "   <b>Consistency</b>\n",
    "\n",
    "    Consistency means that all clients see the same data at the same time, no matter which node they connect to. For this to happen, whenever data is written to one node, it must be instantly forwarded or replicated to all the other nodes in the system before the write is deemed ‘successful.’\n",
    "    \n",
    "   <b>Availability</b>\n",
    "\n",
    "    Availability means that that any client making a request for data gets a response, even if one or more nodes are down. Another way to state this—all working nodes in the distributed system return a valid response for any request, without exception.\n",
    "    \n",
    "   <b>Partition tolerance</b>\n",
    "\n",
    "    Partition is a communications break within a distributed system—a lost or temporarily delayed connection between two nodes. Partition tolerance means that the cluster must continue to work despite any number of communication breakdowns between nodes in the system.\n",
    "\n",
    "### CAP theorem NoSQL database types\n",
    "\n",
    "NoSQL (non-relational) databases are ideal for distributed network applications. Unlike their vertically scalable SQL (relational) counterparts, NoSQL databases are horizontally scalable and distributed by design—they can rapidly scale across a growing network consisting of multiple interconnected nodes. (See \"SQL vs. NoSQL Databases: What's the Difference?\" for more information.)\n",
    "\n",
    "Today, NoSQL databases are classified based on the two CAP characteristics they support:\n",
    "\n",
    "    CP database: A CP database delivers consistency and partition tolerance at the expense of availability. When a partition occurs between any two nodes, the system has to shut down the non-consistent node (i.e., make it unavailable) until the partition is resolved.\n",
    "    \n",
    "    AP database: An AP database delivers availability and partition tolerance at the expense of consistency. When a partition occurs, all nodes remain available but those at the wrong end of a partition might return an older version of data than others. (When the partition is resolved, the AP databases typically resync the nodes to repair all inconsistencies in the system.)\n",
    "    \n",
    "    CA database: A CA database delivers consistency and availability across all nodes. It can’t do this if there is a partition between any two nodes in the system, however, and therefore can’t deliver fault tolerance.\n",
    "\n",
    "We listed this type last for a reason—in a distributed system, partitions can’t be avoided. So, while we can discuss a CA distributed database in theory, for all practical purposes, a CA distributed database can’t exist. However, this doesn’t mean you can’t have a CA database for your distributed application if you need one. Many relational databases, such as PostgreSQL, deliver consistency and availability and can be deployed to multiple nodes using replication.\n",
    "\n",
    "<b>Example 1: Availability<b>\n",
    "\n",
    "Consider, for example, a device installed on an elevator for the purpose of monitoring that elevator. The device posts messages to the main server to provide a status report. If something goes wrong, it will alert the relevant personnel to perform an emergency response. Losing such a message will jeopardize the entire emergency response system, thus selecting availability over consistency in this case will make the most sense.\n",
    "\n",
    "    \n",
    "<b>Example 2: Consistency<b>\n",
    "\n",
    "Consider a reward catalog system that keeps track of allocation and redemption of reward points. During redemption, the system must take care of rewards accumulated at point-in-time, and the transaction should be consistent. Otherwise, one can redeem rewards multiple times. In this case, selection of consistency is most critical.\n",
    "\n",
    "<i>(source: book \"Cosmos DB for MongoDB Developers: Migrating to Azure Cosmos DB and Using the MongoDB API\")<i>\n",
    "\n",
    "### MongoDB and the CAP theorem (CP)\n",
    "\n",
    "MongoDB is a popular NoSQL database management system that stores data as BSON (binary JSON) documents. It's frequently used for big data and real-time applications running at multiple different locations. Relative to the CAP theorem, MongoDB is a CP data store—it resolves network partitions by maintaining consistency, while compromising on availability.\n",
    "\n",
    "MongoDB is a single-master system—each replica set (link resides outside IBM) can have only one primary node that receives all the write operations. All other nodes in the same replica set are secondary nodes that replicate the primary node's operation log and apply it to their own data set. By default, clients also read from the primary node, but they can also specify a read preference (link resides outside IBM) that allows them to read from secondary nodes.\n",
    "\n",
    "When the primary node becomes unavailable, the secondary node with the most recent operation log will be elected as the new primary node. Once all the other secondary nodes catch up with the new master, the cluster becomes available again. As clients can't make any write requests during this interval, the data remains consistent across the entire network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce33acad-f46c-479b-939d-ae5d862cede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import certifi\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# for update doc section\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import pprint\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71af4f3-8343-400e-8e7f-d569fc44ee1d",
   "metadata": {},
   "source": [
    "### To connect a python client, copy the string below and insert there yours password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766837e1-c057-4ce0-bb29-259bf8b6eebe",
   "metadata": {},
   "source": [
    "<img src=\"img/python_connect_1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647730a6-cdb8-4a43-a07e-07a0bf0f99de",
   "metadata": {},
   "source": [
    "<img src=\"img/python_connect_2.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3131117b-4420-4a7e-9b85-18331720a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(db_name) :\n",
    "    from pymongo import MongoClient\n",
    "    import pymongo\n",
    "\n",
    "    # Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "    CONNECTION_STRING = \"mongodb+srv://analytics:analytics-password@mflix.wp9su.mongodb.net/myFirstDatabase\"\n",
    "\n",
    "    # Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "    client = MongoClient(CONNECTION_STRING, tlsCAFile=certifi.where())\n",
    "\n",
    "    # Create the database for our example (we will use the same database throughout the tutorial\n",
    "    return client, client[db_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc57ab6e-09ea-4d9f-b1b9-c2f4a161e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the database\n",
    "mongo_client, dbname = get_database('mflix')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "353ec26c-3049-4c0d-b0be-6d1608a31721",
   "metadata": {},
   "source": [
    "# create collections and insert there a data\n",
    "\n",
    "collection_name = dbname[\"user_1_items\"]\n",
    "\n",
    "item_1 = {\n",
    "\"_id\" : \"U1IT00001\",\n",
    "\"item_name\" : \"Blender\",\n",
    "\"max_discount\" : \"10%\",\n",
    "\"batch_number\" : \"RR450020FRG\",\n",
    "\"price\" : 340,\n",
    "\"category\" : \"kitchen appliance\"\n",
    "}\n",
    "\n",
    "item_2 = {\n",
    "\"_id\" : \"U1IT00002\",\n",
    "\"item_name\" : \"Egg\",\n",
    "\"category\" : \"food\",\n",
    "\"quantity\" : 12,\n",
    "\"price\" : 36,\n",
    "\"item_description\" : \"brown country eggs\"\n",
    "}\n",
    "\n",
    "collection_name.insert_many([item_1,item_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94de222c-f0f9-4776-a8f9-5e43c7b32287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gj310e\\ml_ds\\test\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: database_names is deprecated. Use list_database_names instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data bases:  ['user_shopping_list', 'admin', 'local']\n",
      "collections for user_shopping_list:  ['movies_initial', 'user_1_items']\n"
     ]
    }
   ],
   "source": [
    "print('data bases: ',mongo_client.database_names())\n",
    "print('collections for user_shopping_list: ', mongo_client.user_shopping_list.list_collection_names())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "505ccd02-8222-4606-8cc7-87694888a83e",
   "metadata": {},
   "source": [
    "# drop database\n",
    "# in Atlass -->> Security -->> Database access -->> Edit MongoDB Role (change on -- atlasAdmin@admin --)\n",
    "mongo_client.drop_database('user_shopping_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82776e3f-fe32-4d79-9348-67840ed88d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the csv file as database\n",
    "def csv_to_json(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data_json = json.loads(data.to_json(orient='records'))\n",
    "    return data_json\n",
    "\n",
    "#collection.insert_many(csv_to_json('your_file_path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a97519cd-f4fc-456a-8d95-bdd4ed7a4166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imdbID': 1,\n",
       " 'title': 'Carmencita',\n",
       " 'year': '1894',\n",
       " 'rating': 'NOT RATED',\n",
       " 'runtime': '1 min',\n",
       " 'genre': 'Documentary, Short',\n",
       " 'released': None,\n",
       " 'director': 'William K.L. Dickson',\n",
       " 'writer': None,\n",
       " 'cast': 'Carmencita',\n",
       " 'metacritic': None,\n",
       " 'imdbRating': 5.9,\n",
       " 'imdbVotes': 1032.0,\n",
       " 'poster': 'https://m.media-amazon.com/images/M/MV5BMjAzNDEwMzk3OV5BMl5BanBnXkFtZTcwOTk4OTM5Ng@@._V1_SX300.jpg',\n",
       " 'plot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'fullplot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'language': None,\n",
       " 'country': 'USA',\n",
       " 'awards': None,\n",
       " 'lastupdated': '2015-08-26 00:03:45.040000000',\n",
       " 'type': 'movie'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_to_json('movies_initial.csv')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6dd66-e72c-4d4a-a717-f0579e0fa298",
   "metadata": {},
   "source": [
    "### Each document in a collection is a distinct record. In the movies_initial collection, each document stores data for one movie (see above for one record)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c01da13a-cfe8-45ce-a6bd-08c769e163ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x28e01a14ec8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert csv in collection. First -->> convert to json\n",
    "collection  = dbname[\"movies_initial\"]\n",
    "collection.insert_many(csv_to_json('movies_initial.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0a1ec83-af09-4031-9e8e-d81611a64f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gj310e\\ml_ds\\test\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: database_names is deprecated. Use list_database_names instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data bases:  ['mflix', 'admin', 'local']\n",
      "collections for user_shopping_list:  ['movies_initial']\n"
     ]
    }
   ],
   "source": [
    "print('data bases: ',mongo_client.database_names())\n",
    "print('collections for user_shopping_list: ', mongo_client.mflix.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959cde17-8d03-418a-88de-eed297810999",
   "metadata": {},
   "source": [
    "Depending on where you are in the world, your cluster is probably running on servers physically located in an Amazon AWS data center. This means its in the cloud. I've drawn your MongoDB cluster as three servers because that's what it is. It's a replica set, meaning that three servers are working together to remain in sync, each maintaining a redundant copy of your data. One member of your replica set is always primary, meaning that it's the one that you were communicating with when writing data, and usually when reading data. If the primary stops functioning or loses it's internet connection, another member of the replica set will step in to serve as primary.\n",
    "\n",
    "Since it holds a complete copy of your data, you probably won't even notice if this happens. By default, both Compass and PyMongo are designed to direct the request to whichever node in a replica set is primary, even if the primary changes. For a course like this, it's less important but in production environments this type of high availability is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95954913-3d49-4131-af4e-b92572b98de1",
   "metadata": {},
   "source": [
    "<img src=\"img/mongodb_server.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b94f1313-2201-465d-ba70-382b29424e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['mflix-shard-00-00.wp9su.mongodb.net:27017', 'mflix-shard-00-01.wp9su.mongodb.net:27017', 'mflix-shard-00-02.wp9su.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-2ohrli-shard-0', ssl=True, ssl_ca_certs='c:\\\\users\\\\gj310e\\\\ml_ds\\\\test\\\\venv\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'), 'mflix')\n"
     ]
    }
   ],
   "source": [
    "print(mongo_client.mflix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24646195-3998-4873-97fd-4b1150f8ceca",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "The identifier first stage, always begins with the dollar sign.\n",
    "\n",
    "for every distinct value of language in this collection, this pipeline will create a group and apply the specified accumulator to this group.\n",
    "\n",
    " <i>$sum</i> is one such accumulator. This expression means that for every document matching the identifier for a group, add one to a running count of the documents grouped around that identifier.\n",
    " \n",
    " Now, one big advantage of the aggregation framework is that all the work is done within the database server which has been optimized for the operators the aggregation framework supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ad5c00a8-89d9-47bc-832d-408f7f7f9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the id with certain languages set\n",
    "pipeline = [\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': {\"language\": \"$language\"},\n",
    "            'count': {'$sum': 1}\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e5cac6cd-e237-4bc5-80b3-ae59e385c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count and sort by count the id with certain languages set\n",
    "pipeline = [\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': {\"language\": \"$language\"},\n",
    "            'count': {'$sum': 1}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {'count':-1} # 1: ascending, -1: descending\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e6672d98-e10e-49ce-8d71-7dfff502b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above\n",
    "# simplify\n",
    "# count and sort by count the id with certain languages set\n",
    "pipeline = [\n",
    "    {\n",
    "        '$sortByCount': '$language'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "87335394-386e-4dbd-b4e8-fab5903e6bcb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'English', 'count': 25325},\n",
      " {'_id': 'French', 'count': 1784},\n",
      " {'_id': 'Italian', 'count': 1480},\n",
      " {'_id': 'Japanese', 'count': 1290},\n",
      " {'_id': None, 'count': 1115},\n",
      " {'_id': 'Spanish', 'count': 875},\n",
      " {'_id': 'Russian', 'count': 777},\n",
      " {'_id': 'English, Spanish', 'count': 728},\n",
      " {'_id': 'German', 'count': 674},\n",
      " {'_id': 'English, French', 'count': 584},\n",
      " {'_id': 'Hindi', 'count': 498},\n",
      " {'_id': 'English, North American Indian', 'count': 1},\n",
      " {'_id': 'English, French, German, Serbian', 'count': 1},\n",
      " {'_id': 'English, Mongolian', 'count': 1},\n",
      " {'_id': 'Spanish, Romanian', 'count': 1},\n",
      " {'_id': 'English, Russian, Swedish', 'count': 1},\n",
      " {'_id': 'Armenian, Kurdish, Russian, French', 'count': 1},\n",
      " {'_id': 'English, Spanish, French, Swahili, German', 'count': 1},\n",
      " {'_id': 'Korean, English, Japanese, Cantonese, Mandarin', 'count': 1},\n",
      " {'_id': 'English, Russian, Serbo-Croatian', 'count': 1}]\n"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5606f51c-224f-4abe-8f05-0a1e62e6f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'top language combinations': [{'_id': 'English', 'count': 25325},\n",
      "                                {'_id': 'French', 'count': 1784},\n",
      "                                {'_id': 'Italian', 'count': 1480},\n",
      "                                {'_id': 'Japanese', 'count': 1290},\n",
      "                                {'_id': None, 'count': 1115},\n",
      "                                {'_id': 'Spanish', 'count': 875},\n",
      "                                {'_id': 'Russian', 'count': 777},\n",
      "                                {'_id': 'English, Spanish', 'count': 728},\n",
      "                                {'_id': 'German', 'count': 674},\n",
      "                                {'_id': 'English, French', 'count': 584},\n",
      "                                {'_id': 'Hindi', 'count': 498},\n",
      "                                {'_id': 'Korean', 'count': 377},\n",
      "                                {'_id': 'English, Chinese', 'count': 19},\n",
      "                                {'_id': 'English, Dutch', 'count': 19},\n",
      "                                {'_id': 'German, French', 'count': 18},\n",
      "                                {'_id': 'Georgian', 'count': 18},\n",
      "                                {'_id': 'Croatian', 'count': 17},\n",
      "                                {'_id': 'English, German, Russian',\n",
      "                                 'count': 17},\n",
      "                                {'_id': 'English, Polish', 'count': 17},\n",
      "                                {'_id': 'English, Italian, Spanish',\n",
      "                                 'count': 16},\n",
      "                                {'_id': 'Italian, French', 'count': 16},\n",
      "                                {'_id': 'Norwegian, Swedish', 'count': 16}],\n",
      "  'unusual combinations shared by': [{'_id': {'max': 2, 'min': 1},\n",
      "                                      'language combinations': 1868},\n",
      "                                     {'_id': {'max': 14, 'min': 2},\n",
      "                                      'language combinations': 632},\n",
      "                                     {'_id': {'max': 16, 'min': 14},\n",
      "                                      'language combinations': 11}]}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$sortByCount': \"$language\"\n",
    "    },\n",
    "    {\n",
    "        '$facet': {\n",
    "            'top language combinations': [{'$limit': 100}],\n",
    "            'unusual combinations shared by': [{\n",
    "                '$skip': 100\n",
    "            },\n",
    "            {\n",
    "                '$bucketAuto': {\n",
    "                    'groupBy': \"$count\",\n",
    "                    'buckets': 4,\n",
    "                    'output': {\n",
    "                        'language combinations': {'$sum': 1}\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5bbe6-5161-4bd4-bafe-6f6f3069a9d2",
   "metadata": {},
   "source": [
    "## Filtering on Scalar Fields (we can use \"find\" method)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b600491-3e17-4f4f-99f5-2730dfa9948e",
   "metadata": {},
   "source": [
    "filter = {'language': 'Korean, English'}\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.find(filter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf185c-dddd-4d68-bcda-5adf8db1466d",
   "metadata": {},
   "source": [
    "## Projecting Queries. Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "319e2cff-0e05-42ec-a0a5-8f2dd08e8714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$limit': 100  # limit by 100 documents\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            'title': 2,\n",
    "            'year': 1,\n",
    "            'directors': {'$split': [\"$director\", \", \"]},  # split + rename\n",
    "            'actors': {'$split': [\"$cast\", \", \"]},         # split + rename\n",
    "            'writers': {'$split': [\"$writer\", \", \"]},      # split + rename\n",
    "            'genres': {'$split': [\"$genre\", \", \"]},\n",
    "            'languages': {'$split': [\"$language\", \", \"]},\n",
    "            'countries': {'$split': [\"$country\", \", \"]},\n",
    "            'plot': 1,\n",
    "            'fullPlot': \"$fullplot\", # create the new key \"fullPlot\" with values from \"fullplot\"\n",
    "            'rated': \"$rating\",      # crate new key with values from 'rating'\n",
    "            'released': 1,\n",
    "            'runtime': 1,\n",
    "            'poster': 1,\n",
    "            'imdb': {                # create embedding document (dictionary)\n",
    "                'id': \"$imdbID\",\n",
    "                'rating': \"$imdbRating\",\n",
    "                'votes': \"$imdbVotes\"\n",
    "                },\n",
    "            'metacritic': 1,\n",
    "            'awards': 1,\n",
    "            'type': 1,\n",
    "            'lastUpdated': \"$lastupdated\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$out': \"movies_scratch\"  # output -->> NEW COLLECTION WITH NAME \"movies_scratch\"\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad88ab-8dde-4ffa-9b72-93c82efad926",
   "metadata": {},
   "source": [
    "## Projecting Queries. Part 2 (condiiton, create timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a03d9e8b-0cf3-42ae-83f7-4e2dbb182123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        '$limit': 100\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            'title': 1,\n",
    "            'year': 1,\n",
    "            'directors': {'$split': [\"$director\", \", \"]},\n",
    "            'actors': {'$split': [\"$cast\", \", \"]},\n",
    "            'writers': {'$split': [\"$writer\", \", \"]},\n",
    "            'genres': {'$split': [\"$genre\", \", \"]},\n",
    "            'languages': {'$split': [\"$language\", \", \"]},\n",
    "            'countries': {'$split': [\"$country\", \", \"]},\n",
    "            'plot': 1,\n",
    "            'fullPlot': \"$fullplot\",\n",
    "            'rated': \"$rating\",\n",
    "            'released': {   \n",
    "                '$cond': {                            # conditional operation\n",
    "                    'if': {'$ne': [\"$released\", \"\"]}, # $ne -->> not equal to..    here -->> if \"$released\" not equal to \"\" (None)\n",
    "                    'then': {\n",
    "                        '$dateFromString': {                  # $dateFromString is aggregation operator\n",
    "                            'dateString': \"$released\"         # in the output field \"released\" -->> will b null or timestamp\n",
    "                        }\n",
    "                    },\n",
    "                    'else': \"\"}},\n",
    "            'runtime': 1,\n",
    "            'poster': 1,\n",
    "            'imdb': {\n",
    "                'id': \"$imdbID\",\n",
    "                'rating': \"$imdbRating\",\n",
    "                'votes': \"$imdbVotes\"\n",
    "                },\n",
    "            'metacritic': 1,\n",
    "            'awards': 1,\n",
    "            'type': 1,\n",
    "            'lastUpdated': \"$lastupdated\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$out': \"movies_scratch\"\n",
    "    }\n",
    "]\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7649ca-f7af-4ee7-8f79-320eed7865d9",
   "metadata": {},
   "source": [
    "## Projecting Queries. Part 2 (condiiton, create timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "90150f4a-0a7f-4e53-b73f-7182c84c0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Like the last handout, this pipeline will not work on Atlas until MongoDB 3.6 has been released\n",
    "# If you're testing this before 3.6 is released you can download and install MongoDB 3.5.X locally\n",
    "# In that case you should use \"mongodb://localhost:27017\" as your connection URI\n",
    "\n",
    "pipeline = [\n",
    "    {\n",
    "        '$limit': 100\n",
    "    },\n",
    "    {\n",
    "        '$addFields': {                     # we need to separate miliseconds (after point -->> lastupdated: \"2015-08-26 00:03:45.040000000\")\n",
    "            'lastupdated': {                #  insert \"lastupdated\" field. If it exist, just replace it\n",
    "                '$arrayElemAt': [           # so we get here lastupdated: \"2015-08-26 00:03:45\"  (without miliseconds)\n",
    "                    {'$split': [\"$lastupdated\", \".\"]},\n",
    "                    0\n",
    "                ]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$project': {\n",
    "            'title': 1,\n",
    "            'year': 1,\n",
    "            'directors': {'$split': [\"$director\", \", \"]},\n",
    "            'actors': {'$split': [\"$cast\", \", \"]},\n",
    "            'writers': {'$split': [\"$writer\", \", \"]},\n",
    "            'genres': {'$split': [\"$genre\", \", \"]},\n",
    "            'languages': {'$split': [\"$language\", \", \"]},\n",
    "            'countries': {'$split': [\"$country\", \", \"]},\n",
    "            'plot': 1,\n",
    "            'fullPlot': \"$fullplot\",\n",
    "            'rated': \"$rating\",\n",
    "            'released': {\n",
    "                '$cond': {\n",
    "                    'if': {'$ne': [\"$released\", \"\"]},\n",
    "                    'then': {\n",
    "                        '$dateFromString': {\n",
    "                            'dateString': \"$released\"\n",
    "                        }\n",
    "                    },\n",
    "                    'else': \"\"}},\n",
    "            'runtime': 1,\n",
    "            'poster': 1,\n",
    "            'imdb': {\n",
    "                'id': \"$imdbID\",\n",
    "                'rating': \"$imdbRating\",\n",
    "                'votes': \"$imdbVotes\"\n",
    "                },\n",
    "            'metacritic': 1,\n",
    "            'awards': 1,\n",
    "            'type': 1,\n",
    "            'lastUpdated': {\n",
    "                '$cond': {\n",
    "                    'if': {'$ne': [\"$lastupdated\", \"\"]},\n",
    "                    'then': {\n",
    "                        '$dateFromString': {\n",
    "                            'dateString': \"$lastupdated\",\n",
    "                            'timezone': \"America/New_York\"\n",
    "                        }\n",
    "                    },\n",
    "                    'else': \"\"}}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$out': \"movies_scratch\"\n",
    "    }\n",
    "]\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(mongo_client.mflix.movies_initial.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad345851-93b8-4074-8a6a-9d2ca166b5bb",
   "metadata": {},
   "source": [
    "## Updating Documents 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a6f886da-e3f1-47a2-994c-ceec9aa8ea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x28e1f17d3c8>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new collection (same data)\n",
    "# insert csv in collection. First -->> convert to json\n",
    "collection  = dbname[\"movies\"]\n",
    "collection.insert_many(csv_to_json('movies_initial.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "07ac7d25-be2f-4fe5-b420-f95f7074d899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'$set': {'cast': ['Carmencita'],\n",
      "          'countries': ['USA'],\n",
      "          'directors': ['William K.L. Dickson'],\n",
      "          'fullPlot': 'Performing on what looks like a small wooden stage, '\n",
      "                      'wearing a dress with a hoop skirt and white high-heeled '\n",
      "                      'pumps, Carmencita does a dance with kicks and twirls, a '\n",
      "                      'smile always on her face.',\n",
      "          'genres': ['Documentary', 'Short'],\n",
      "          'imdb': {'id': 1, 'rating': 5.9, 'votes': 1032.0},\n",
      "          'rated': 'NOT RATED',\n",
      "          'runtime': 1},\n",
      " '$unset': {'awards': '',\n",
      "            'country': '',\n",
      "            'director': '',\n",
      "            'fullplot': '',\n",
      "            'genre': '',\n",
      "            'imdbID': '',\n",
      "            'imdbRating': '',\n",
      "            'imdbVotes': '',\n",
      "            'language': '',\n",
      "            'metacritic': '',\n",
      "            'rating': '',\n",
      "            'released': '',\n",
      "            'writer': ''}}\n"
     ]
    }
   ],
   "source": [
    "runtime_pat = re.compile(r'([0-9]+) min')\n",
    "\n",
    "for movie in mongo_client.mflix.movies.find({}):  # iterate thru each document in collection\n",
    "\n",
    "    fields_to_set = {}\n",
    "    fields_to_unset = {}\n",
    "\n",
    "    for k,v in movie.copy().items():             # loop thru each key in document\n",
    "        if v == \"\" or v == [\"\"] or v==None:\n",
    "            del movie[k]\n",
    "            fields_to_unset[k] = \"\"\n",
    "\n",
    "    if 'director' in movie:\n",
    "        fields_to_unset['director'] = \"\"\n",
    "        fields_to_set['directors'] = movie['director'].split(\", \")\n",
    "    if 'cast' in movie:\n",
    "        fields_to_set['cast'] = movie['cast'].split(\", \")\n",
    "    if 'writer' in movie:\n",
    "        fields_to_unset['writer'] = \"\"\n",
    "        fields_to_set['writers'] = movie['writer'].split(\", \")\n",
    "    if 'genre' in movie:\n",
    "        fields_to_unset['genre'] = \"\"\n",
    "        fields_to_set['genres'] = movie['genre'].split(\", \")\n",
    "    if 'language' in movie:\n",
    "        fields_to_unset['language'] = \"\"\n",
    "        fields_to_set['languages'] = movie['language'].split(\", \")\n",
    "    if 'country' in movie:\n",
    "        fields_to_unset['country'] = \"\"\n",
    "        fields_to_set['countries'] = movie['country'].split(\", \")\n",
    "        \n",
    "    if 'fullplot' in movie:\n",
    "        fields_to_unset['fullplot'] = \"\"\n",
    "        fields_to_set['fullPlot'] = movie['fullplot']\n",
    "    if 'rating' in movie:\n",
    "        fields_to_unset['rating'] = \"\"\n",
    "        fields_to_set['rated'] = movie['rating']\n",
    "\n",
    "    imdb = {}\n",
    "    if 'imdbID' in movie:\n",
    "        fields_to_unset['imdbID'] = \"\"\n",
    "        imdb['id'] = movie['imdbID']\n",
    "    if 'imdbRating' in movie:\n",
    "        fields_to_unset['imdbRating'] = \"\"\n",
    "        imdb['rating'] = movie['imdbRating']\n",
    "    if 'imdbVotes' in movie:\n",
    "        fields_to_unset['imdbVotes'] = \"\"\n",
    "        imdb['votes'] = movie['imdbVotes']\n",
    "    if imdb:\n",
    "        fields_to_set['imdb'] = imdb\n",
    "        \n",
    "    if 'released' in movie:\n",
    "        fields_to_set['released'] = datetime.strptime(movie['released'],\n",
    "                                                      \"%Y-%m-%d\")\n",
    "    if 'lastUpdated' in movie:\n",
    "        fields_to_set['lastUpdated'] = datetime.strptime(movie['lastUpdated'][0:19],\n",
    "                                                         \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if 'runtime' in movie:                             # extract integer with regular expression\n",
    "        m = runtime_pat.match(movie['runtime']) \n",
    "        if m:\n",
    "            fields_to_set['runtime'] = int(m.group(1))\n",
    "\n",
    "    update_doc = {}\n",
    "    if fields_to_set:\n",
    "        update_doc['$set'] = fields_to_set\n",
    "    if fields_to_unset:\n",
    "        update_doc['$unset'] = fields_to_unset\n",
    "    pprint.pprint(update_doc)\n",
    "    \n",
    "    # put a break here since the algorithm is working to long\n",
    "    # updating per each document is not the best idea\n",
    "    break\n",
    "    #db.movies.update_one({'_id': movie['_id']}, update_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ed858394-a26f-4386-98d0-3cef0ee56fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'889'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime_pat = re.compile(r'\\D*([0-9]+)')\n",
    "runtime_pat.match('889 min').group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffcd7f-b104-4aea-9e0c-2cd05d3b5230",
   "metadata": {},
   "source": [
    "## Updating In Batch\n",
    "\n",
    "The difference is using an \"UpdateOne\" class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d3225e8-7a05-48ed-b954-62a4b0121dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, UpdateOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1199c664-08f9-4531-bb3b-99b75e8ad5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_pat = re.compile(r'([0-9]+) min')\n",
    "\n",
    "batch_size = 1000\n",
    "updates = []\n",
    "count = 0\n",
    "for movie in mongo_client.mflix.movies.find({}):\n",
    "\n",
    "    fields_to_set = {}\n",
    "    fields_to_unset = {}\n",
    "\n",
    "    for k,v in movie.copy().items():\n",
    "        if v == \"\" or v == [\"\"] or v==None:\n",
    "            del movie[k]\n",
    "            fields_to_unset[k] = \"\"\n",
    "\n",
    "    if 'director' in movie:\n",
    "        fields_to_unset['director'] = \"\"\n",
    "        fields_to_set['directors'] = movie['director'].split(\", \")\n",
    "    if 'cast' in movie:\n",
    "        fields_to_set['cast'] = movie['cast'].split(\", \")\n",
    "    if 'writer' in movie:\n",
    "        fields_to_unset['writer'] = \"\"\n",
    "        fields_to_set['writers'] = movie['writer'].split(\", \")\n",
    "    if 'genre' in movie:\n",
    "        fields_to_unset['genre'] = \"\"\n",
    "        fields_to_set['genres'] = movie['genre'].split(\", \")\n",
    "    if 'language' in movie:\n",
    "        fields_to_unset['language'] = \"\"\n",
    "        fields_to_set['languages'] = movie['language'].split(\", \")\n",
    "    if 'country' in movie:\n",
    "        fields_to_unset['country'] = \"\"\n",
    "        fields_to_set['countries'] = movie['country'].split(\", \")\n",
    "        \n",
    "    if 'fullplot' in movie:\n",
    "        fields_to_unset['fullplot'] = \"\"\n",
    "        fields_to_set['fullPlot'] = movie['fullplot']\n",
    "    if 'rating' in movie:\n",
    "        fields_to_unset['rating'] = \"\"\n",
    "        fields_to_set['rated'] = movie['rating']\n",
    "\n",
    "    imdb = {}\n",
    "    if 'imdbID' in movie:\n",
    "        fields_to_unset['imdbID'] = \"\"\n",
    "        imdb['id'] = movie['imdbID']\n",
    "    if 'imdbRating' in movie:\n",
    "        fields_to_unset['imdbRating'] = \"\"\n",
    "        imdb['rating'] = movie['imdbRating']\n",
    "    if 'imdbVotes' in movie:\n",
    "        fields_to_unset['imdbVotes'] = \"\"\n",
    "        imdb['votes'] = movie['imdbVotes']\n",
    "    if imdb:\n",
    "        fields_to_set['imdb'] = imdb\n",
    "        \n",
    "    if 'released' in movie:\n",
    "        fields_to_set['released'] = datetime.strptime(movie['released'],\n",
    "                                                      \"%Y-%m-%d\")\n",
    "    if 'lastupdated' in movie:\n",
    "        fields_to_set['lastUpdated'] = datetime.strptime(movie['lastUpdated'][0:19],\n",
    "                                                         \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if 'runtime' in movie:\n",
    "        m = runtime_pat.match(movie['runtime']) \n",
    "        if m:\n",
    "            fields_to_set['runtime'] = int(m.group(1))\n",
    "\n",
    "    update_doc = {}\n",
    "    if fields_to_set:\n",
    "        update_doc['$set'] = fields_to_set\n",
    "    if fields_to_unset:\n",
    "        update_doc['$unset'] = fields_to_unset\n",
    "\n",
    "    # use UpdateOne class    \n",
    "    updates.append(UpdateOne({'_id': movie['_id']}, update_doc))\n",
    "\n",
    "    count += 1\n",
    "    if count == batch_size:\n",
    "        mongo_client.mflix.movies.bulk_write(updates)\n",
    "        updates = []\n",
    "        count = 0\n",
    "\n",
    "if updates:         \n",
    "    mongo_client.mflix.movies.bulk_write(updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49acb7-2587-4512-af95-8a17c1d854ee",
   "metadata": {},
   "source": [
    "## Data Types in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f624937b-ef5b-4a84-938a-d4fd3ba7b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = mongo_client.mflix.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "12732b07-1e5f-4840-8c62-6d242e1c50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = movies.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7e311-fd4f-49f5-b814-57cd7af9794e",
   "metadata": {},
   "source": [
    "<b>Object</b>\n",
    "\n",
    "ObjectId is actually a MongoDB data type. And it's special because what it allows us to do is it allows MongoDB to identify, uniquely, every document in the database. And it's able to accomplish this because this random string of characters is actually composed of the current time in unix, the ID of the machine that is running this, the process ID, and as well as a counter that starts with a random value. And through all of these different pieces, MongoDB is able to, with somewhat good certainty, ensure that this ObjectId is unique. And is able to therefore uniquely identify every document in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "88c6d0fc-b7dd-4579-9bdd-23b44f37fff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('60f55005fbb85be58d48b74a')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca172d-51a9-4191-89c8-fae10435b652",
   "metadata": {},
   "source": [
    "<b>Date</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "07ebc5f6-ab22-430f-a606-bd099aaf4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = mongo_client['test']['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eeafbb1d-6f3f-4e57-85e5-97a89bf56ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['mflix-shard-00-00.wp9su.mongodb.net:27017', 'mflix-shard-00-01.wp9su.mongodb.net:27017', 'mflix-shard-00-02.wp9su.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', replicaset='atlas-2ohrli-shard-0', ssl=True, ssl_ca_certs='c:\\\\users\\\\gj310e\\\\ml_ds\\\\test\\\\venv\\\\lib\\\\site-packages\\\\certifi\\\\cacert.pem'), 'test'), 'dates')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6a6e9ca5-638a-4265-a037-09980d1cb201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x28e01ed5108>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.insert_one({ \"dt\": datetime.utcnow() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "16d3da82-6817-4820-b73f-d48a17c06f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('60f55cf1fbb85be58d496b08'),\n",
       " 'dt': datetime.datetime(2021, 7, 19, 11, 7, 29, 811000)}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4512ccf-5c4b-401e-b16b-4f3c8bea4cf3",
   "metadata": {},
   "source": [
    "<b>Decimal128</b>\n",
    "\n",
    "So we don't want any rounding errors when you're doing math with money. And so when we are using money and storing it in MongoDB, we really want to use the Decimal128 data type so there's no rounding errors. And so MongoDB natively supports this. And so we can go ahead and import this special data type from the bson library. And then insert a document, pretty simple, the API is very simple. You just wrap your number as a string and then wrap that in the Decimal128 function. And then, as you can see, we've successfully inserted it. And now I can easily find it. And you can see that this is stored kind of exactly as the way we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3d084abb-55b8-44cc-937a-b1a7c6edcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.decimal128 import Decimal128\n",
    "decimals = mongo_client['test']['decimals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2e36e7f8-6a87-4f3c-80d1-763c9381d512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x28e0db00448>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimals.insert_one({ \"money\": Decimal128(\"99.97\") })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "df139f14-92dd-4f99-b1a4-f18a2f74ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('60f55e77fbb85be58d496b09'), 'money': Decimal128('99.99')}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimals.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68357e0-755b-462f-8870-63ae80ff1b5b",
   "metadata": {},
   "source": [
    "<b>Query base on data type</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6fc4e8c2-1e44-42da-8ed6-4b735abf55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('60f55005fbb85be58d48b74a'),\n",
       " 'title': 'Carmencita',\n",
       " 'year': '1894',\n",
       " 'runtime': 1,\n",
       " 'cast': ['Carmencita'],\n",
       " 'poster': 'https://m.media-amazon.com/images/M/MV5BMjAzNDEwMzk3OV5BMl5BanBnXkFtZTcwOTk4OTM5Ng@@._V1_SX300.jpg',\n",
       " 'plot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'lastupdated': '2015-08-26 00:03:45.040000000',\n",
       " 'type': 'movie',\n",
       " 'countries': ['USA'],\n",
       " 'directors': ['William K.L. Dickson'],\n",
       " 'fullPlot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'genres': ['Documentary', 'Short'],\n",
       " 'imdb': {'id': 1, 'rating': 5.9, 'votes': 1032.0},\n",
       " 'rated': 'NOT RATED'}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = mongo_client.mflix.movies\n",
    "movies.find_one({ \"year\": { \"$type\": \"string\" } })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "58884dc1-6761-4117-a03e-713b7f208c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a cursor (all elements) which has { \"year\": { \"$type\": \"string\" } }\n",
    "kk = movies.find({ \"year\": { \"$type\": \"string\" } })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "a32d24e5-f379-4171-9a86-2774043b1123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('60f55005fbb85be58d48b74a'),\n",
       " 'title': 'Carmencita',\n",
       " 'year': '1894',\n",
       " 'runtime': 1,\n",
       " 'cast': ['Carmencita'],\n",
       " 'poster': 'https://m.media-amazon.com/images/M/MV5BMjAzNDEwMzk3OV5BMl5BanBnXkFtZTcwOTk4OTM5Ng@@._V1_SX300.jpg',\n",
       " 'plot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'lastupdated': '2015-08-26 00:03:45.040000000',\n",
       " 'type': 'movie',\n",
       " 'countries': ['USA'],\n",
       " 'directors': ['William K.L. Dickson'],\n",
       " 'fullPlot': 'Performing on what looks like a small wooden stage, wearing a dress with a hoop skirt and white high-heeled pumps, Carmencita does a dance with kicks and twirls, a smile always on her face.',\n",
       " 'genres': ['Documentary', 'Short'],\n",
       " 'imdb': {'id': 1, 'rating': 5.9, 'votes': 1032.0},\n",
       " 'rated': 'NOT RATED'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "01f39297-ca28-49bc-af47-797631f911ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('60f55005fbb85be58d48b74b'),\n",
       " 'title': 'Blacksmith Scene',\n",
       " 'year': '1893',\n",
       " 'runtime': 1,\n",
       " 'released': datetime.datetime(1893, 5, 9, 0, 0),\n",
       " 'cast': ['Charles Kayser', 'John Ott'],\n",
       " 'plot': 'Three men hammer on an anvil and pass a bottle of beer around.',\n",
       " 'awards': '1 win.',\n",
       " 'lastupdated': '2015-08-26 00:03:50.133000000',\n",
       " 'type': 'movie',\n",
       " 'countries': ['USA'],\n",
       " 'directors': ['William K.L. Dickson'],\n",
       " 'fullPlot': 'A stationary camera looks at a large anvil with a blacksmith behind it and one on either side. The smith in the middle draws a heated metal rod from the fire, places it on the anvil, and all three begin a rhythmic hammering. After several blows, the metal goes back in the fire. One smith pulls out a bottle of beer, and they each take a swig. Then, out comes the glowing metal and the hammering resumes.',\n",
       " 'genres': ['Short'],\n",
       " 'imdb': {'id': 5, 'rating': 6.2, 'votes': 1189.0},\n",
       " 'rated': 'UNRATED'}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2b9d7-6705-4190-b84c-5cd95616a83a",
   "metadata": {},
   "source": [
    "## Filtering on Array Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a088dd-553c-48b1-89be-b8aef3c9a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "CONNECTION_STRING = \"mongodb+srv://analytics:analytics-password@mflix.wp9su.mongodb.net/myFirstDatabase\"\n",
    "# Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "client = MongoClient(CONNECTION_STRING, tlsCAFile=certifi.where())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664e2506-ff6d-431b-9412-3ea3004479fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = client.mflix.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33af3a1b-299b-4e64-965b-c7e065fa717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('60f55005fbb85be58d48ca0b'),\n",
      "  'cast': ['Rock Hudson', 'Anna Kashfi', 'Dan Duryea', 'Don DeFore'],\n",
      "  'countries': ['USA'],\n",
      "  'directors': ['Douglas Sirk'],\n",
      "  'fullPlot': 'Dean Hess, who entered the ministry to atone for bombing a '\n",
      "              \"German orphanage, decides he's a failure at preaching. Rejoined \"\n",
      "              'to train pilots early in the Korean War, he finds Korean '\n",
      "              'orphans raiding the airbase garbage. With a pretty Korean '\n",
      "              'teacher, he sets up an orphanage for them and others. But he '\n",
      "              'finds that to protect his charges, he has to kill.',\n",
      "  'genres': ['Biography', 'Drama', 'History'],\n",
      "  'imdb': {'id': 50171, 'rating': 6.3, 'votes': 654.0},\n",
      "  'languages': ['English', 'Korean'],\n",
      "  'lastupdated': '2015-09-02 00:25:52.287000000',\n",
      "  'plot': 'A remorseful bomber pilot-turned-minister rejoins for the Korean '\n",
      "          'War.',\n",
      "  'poster': 'https://m.media-amazon.com/images/M/MV5BMTIwMjIzNTYzMl5BMl5BanBnXkFtZTcwOTIxMTUyMQ@@._V1_SX300.jpg',\n",
      "  'rated': 'APPROVED',\n",
      "  'released': datetime.datetime(1957, 3, 3, 0, 0),\n",
      "  'runtime': 108,\n",
      "  'title': 'Battle Hymn',\n",
      "  'type': 'movie',\n",
      "  'writers': ['Charles Grayson', 'Vincent B. Evans'],\n",
      "  'year': '1957'},\n",
      " {'_id': ObjectId('60f55005fbb85be58d48cac7'),\n",
      "  'cast': ['Richard Widmark',\n",
      "           'Richard Basehart',\n",
      "           'Dolores Michaels',\n",
      "           'June Lockhart'],\n",
      "  'countries': ['USA'],\n",
      "  'directors': ['Karl Malden'],\n",
      "  'fullPlot': 'Military investigator Colonel Edwards is assigned a case '\n",
      "              'involving Major Cargill, a Korean War POW who is accused of '\n",
      "              \"treason. Although Cargill admits his guilt and Edwards' \"\n",
      "              'superiors are impatiently pushing Edwards to move this case to '\n",
      "              \"court martial, Edwards becomes convinced of Cargill's \"\n",
      "              'innocence.',\n",
      "  'genres': ['Drama', 'War'],\n",
      "  'imdb': {'id': 51083, 'rating': 7.3, 'votes': 719.0},\n",
      "  'languages': ['English', 'Korean'],\n",
      "  'lastupdated': '2015-08-26 00:01:14.620000000',\n",
      "  'plot': 'During the Korean War former POW Major Cargill admits to having '\n",
      "          'collaborated with the enemy but military investigator Colonel '\n",
      "          'Edwards wants the details.',\n",
      "  'poster': 'https://m.media-amazon.com/images/M/MV5BMTU2NzU1Nzg5Nl5BMl5BanBnXkFtZTcwMjgyMTM4NA@@._V1_SX300.jpg',\n",
      "  'rated': 'APPROVED',\n",
      "  'released': datetime.datetime(1957, 10, 23, 0, 0),\n",
      "  'runtime': 96,\n",
      "  'title': 'Time Limit',\n",
      "  'type': 'movie',\n",
      "  'writers': ['Henry Denker (screenplay)',\n",
      "              'Henry Denker (play)',\n",
      "              'Ralph Berkey (play)'],\n",
      "  'year': '1957'}]\n"
     ]
    }
   ],
   "source": [
    "filter = {\n",
    "    'languages': {'$all': ['Korean', 'English']}   # if '$all' is used -->> find ['Korean', 'English'] and ['English', 'Korean']\n",
    "}\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(movies.find(filter))[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee3f09a-f1bc-4c7f-8a29-8d2bfbacbcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('60f55005fbb85be58d490ee0'),\n",
      "  'awards': '1 win.',\n",
      "  'cast': ['Jock Mahoney', 'Pat Yi', 'Youngson Chon', 'Dong-hwi Jang'],\n",
      "  'countries': ['South Korea', 'USA'],\n",
      "  'directors': ['Man-hui Lee'],\n",
      "  'fullPlot': 'A division of marines survive a battle with the Chinese army '\n",
      "              'but find themselves stranded without contact on the wrong side '\n",
      "              'of the front.',\n",
      "  'genres': ['Drama', 'War'],\n",
      "  'imdb': {'id': 239594, 'rating': 6.9, 'votes': 60.0},\n",
      "  'languages': ['Korean', 'English'],\n",
      "  'lastupdated': '2015-08-17 00:00:04.390000000',\n",
      "  'plot': 'A division of marines survive a battle with the Chinese army but '\n",
      "          'find themselves stranded without contact on the wrong side of the '\n",
      "          'front.',\n",
      "  'released': datetime.datetime(1966, 2, 1, 0, 0),\n",
      "  'runtime': 88,\n",
      "  'title': 'Marine Battleground',\n",
      "  'type': 'movie',\n",
      "  'writers': ['Kook-jin Jang (story)', 'Milton Mann', 'Han-chul Yu'],\n",
      "  'year': '1963'}]\n"
     ]
    }
   ],
   "source": [
    "filter = {\n",
    "    'languages': ['Korean', 'English']   # find only ['Korean', 'English']  (other languages also coulb be here)\n",
    "}\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(movies.find(filter))[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33085c40-51fd-48e0-be69-3f0927791a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('60f55005fbb85be58d48d2b8'),\n",
      "  'languages': ['Korean'],\n",
      "  'title': 'Yongary, Monster from the Deep'},\n",
      " {'_id': ObjectId('60f55005fbb85be58d48e98a'),\n",
      "  'languages': ['Korean'],\n",
      "  'title': 'Bulgasari'}]\n"
     ]
    }
   ],
   "source": [
    "# find movies with Korean language in the first place ('languages.0'), in the second place will be 'languages.1'\n",
    "\n",
    "filter = {\n",
    "    'languages.0': 'Korean' \n",
    "}\n",
    "\n",
    "# make projection: include title and language. \n",
    "projection = {\n",
    "    'title': 1,\n",
    "    'languages': 1\n",
    "}\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(movies.find(filter, projection))[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aec182-cb2e-4ffd-ab95-974c34c94901",
   "metadata": {},
   "source": [
    "#### '_id' field as unique identifier automaticaly. So we need manualy exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bae3027f-9166-4bc2-9958-f482732fe348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'languages': ['Korean'], 'title': 'Yongary, Monster from the Deep'},\n",
      " {'languages': ['Korean'], 'title': 'Bulgasari'}]\n"
     ]
    }
   ],
   "source": [
    "# make projection: include title and language. \n",
    "projection = {\n",
    "    '_id': 0,\n",
    "    'title': 1,\n",
    "    'languages': 1\n",
    "}\n",
    "\n",
    "clear_output()\n",
    "pprint.pprint(list(movies.find(filter, projection))[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15105c0a-9c8a-420f-9a37-54f0c6677cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958a111-b66a-4ab7-b5ad-9c607aba3ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
